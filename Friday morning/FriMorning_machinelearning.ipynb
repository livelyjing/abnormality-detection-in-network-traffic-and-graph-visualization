{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_files = [\n",
    "    'Monday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Wednesday-workingHours.pcap_ISCX.csv',\n",
    "    'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "    # 'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "    # 'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "    # 'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "]\n",
    "\n",
    "days = [\n",
    "    # 'Monday',\n",
    "    # 'Tuesday',\n",
    "    # 'Wednesday',\n",
    "    # 'Thursday',\n",
    "    'Friday'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import numpy as np\n",
    "\n",
    "def balancing(rawDataFrame):\n",
    "    # Preprocessing\n",
    "    rawDataFrame['Label'] = rawDataFrame['Label'].apply(lambda x: 'BENIGN' if x == 'BENIGN' else 'Abnormal')\n",
    "    rawDataFrame = rawDataFrame.drop(rawDataFrame[pd.isnull(rawDataFrame['Flow ID'])].index)\n",
    "    rawDataFrame.replace('Infinity', -1, inplace=True)\n",
    "    rawDataFrame.replace([np.inf, -np.inf, np.nan], -1, inplace=True)\n",
    "    rawDataFrame[['Flow Bytes/s', 'Flow Packets/s']] = rawDataFrame[['Flow Bytes/s','Flow Packets/s']].apply(pd.to_numeric)\n",
    "    \n",
    "    rawDataFrame = rawDataFrame.loc[rawDataFrame['Flow Bytes/s'] > 0]\n",
    "    rawDataFrame = rawDataFrame.loc[rawDataFrame['Flow Packets/s'] > 0]\n",
    "    rawDataFrame = rawDataFrame.loc[rawDataFrame['Flow Duration'] > 0]\n",
    "\n",
    "    rawDataFrame.to_csv('./beforelog.csv')\n",
    "\n",
    "    # Log transformation of each variable\n",
    "    rawDataFrame['Flow Bytes/s'] = np.log(rawDataFrame['Flow Bytes/s']) \n",
    "    rawDataFrame['Flow Packets/s'] = np.log(rawDataFrame['Flow Packets/s'])\n",
    "    rawDataFrame['Flow Duration'] = np.log(rawDataFrame['Flow Duration'])\n",
    "\n",
    "    attack_df = rawDataFrame.loc[rawDataFrame['Label'] != 'BENIGN']\n",
    "    attack_df.to_csv('./attack.csv')\n",
    "    attack_count = len(attack_df.index)\n",
    "    print(attack_count)\n",
    "    raw_normal_df = rawDataFrame.loc[rawDataFrame['Label'] == 'BENIGN']\n",
    "    raw_normal_df.to_csv('./benign.csv')\n",
    "    log_raw_df = pd.concat([attack_df, raw_normal_df])\n",
    "    log_raw_df.to_csv('./logRawFri.csv')\n",
    "    \n",
    "    normal_count = int(floor(attack_count / 30 * 70))\n",
    "    normal_df = rawDataFrame.loc[rawDataFrame['Label'] == 'BENIGN'].sample(normal_count)\n",
    "    normal_df.to_csv('./normal.csv')\n",
    "    normal_count = len(normal_df.index)\n",
    "    print(normal_count)\n",
    "    log_final_df = pd.concat([attack_df, normal_df])\n",
    "    log_final_df.to_csv('./logFri.csv')\n",
    "    return pd.concat([attack_df, normal_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def hyperparameter_selection(balancedDataFrame):\n",
    "    excluded = ['Flow ID', 'Source IP', 'Source Port',\n",
    "                'Destination IP', 'Destination Port', 'Protocol', 'Timestamp']\n",
    "    balancedDataFrame = balancedDataFrame.drop(columns=excluded, errors='ignore')\n",
    "    balancedDataFrame['Label'] = balancedDataFrame['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "    \n",
    "    \n",
    "    # Find best estimator\n",
    "    y = balancedDataFrame['Label'].values\n",
    "    X = balancedDataFrame.drop(columns=['Label'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=np.random.seed(42))\n",
    "    X_train.shape, X_test.shape\n",
    "    rfc = RandomForestClassifier(random_state=np.random.seed(42))\n",
    "    #scoring = {'f1', 'accuracy'}\n",
    "    # print(scoring)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    parameters = {\n",
    "        'n_estimators': [20, 40, 60],\n",
    "        'min_samples_leaf': [2, 4, 6],\n",
    "        'max_features': [4, 6, 8],\n",
    "        'max_depth': [13, 15, 17]\n",
    "    }\n",
    "    gcv = GridSearchCV(rfc, parameters, scoring=['f1', 'accuracy'],\n",
    "                      refit= 'f1', cv=3, return_train_score=True)\n",
    "    gcv.fit(X_train, y_train)\n",
    "    \n",
    "    # The best score produced on the test folds from your training data\n",
    "    best_score = gcv.best_score_\n",
    "    print (f'Best score: {best_score}')\n",
    "    # The accuracy on the test set\n",
    "    accuracy = gcv.score(X_test, y_test) \n",
    "    print (f'Accuracy: {accuracy}')\n",
    "\n",
    "    return [gcv.best_estimator_, gcv.best_params_, gcv.best_score_]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "\n",
    "def score(givenDataFrame, model_config):\n",
    "    givenDataFrame.to_csv('./actual.csv')\n",
    "\n",
    "    \n",
    "    # Prepare training data & testing data\n",
    "    excluded = ['Flow ID', 'Source IP', 'Source Port',\n",
    "                'Destination IP', 'Destination Port', 'Protocol', 'Timestamp']\n",
    "    excluded_df = givenDataFrame[excluded]\n",
    "    excluded_df.to_csv('./excluded.csv')\n",
    "    givenDataFrame = givenDataFrame.drop(columns=excluded, errors='ignore')\n",
    "    givenDataFrame['Label'] = givenDataFrame['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "    \n",
    "    y = givenDataFrame['Label'].values\n",
    "    X = givenDataFrame.drop(columns=['Label'])\n",
    "    beforepredict_df = X\n",
    "    beforepredict_df.to_csv('./beforepredict.csv')\n",
    "    print(f'Given DataFrame shape: {X.shape}')\n",
    "    print(f'Label shape: {y.shape}')\n",
    "    print(f'Labels: {givenDataFrame[\"Label\"].unique()}')\n",
    "\n",
    "    \n",
    "    # Training Data into model\n",
    "    rfc = model_config[0]\n",
    "\n",
    "    # List out important features\n",
    "    features = X.columns\n",
    "    importances = rfc.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    for index, i in enumerate(indices[:8]):\n",
    "        print('{}.\\t#{}\\t{:.3f}\\t{}'.format(\n",
    "        index + 1, i, importances[i], features[i]))\n",
    "\n",
    "    # Predict\n",
    "    y_pred = rfc.predict(X)\n",
    "    pd.DataFrame(y_pred).to_csv('./randompredict.csv')\n",
    "    print ({X.shape})\n",
    "    print ({y_pred.shape})\n",
    "\n",
    "    predict_df = excluded_df.join(X).join(pd.DataFrame(y_pred, index = X.index, columns=['Label']))\n",
    "    predict_df['Label'] = predict_df['Label'].apply(lambda x: 'BENIGN' if x == 0 else 'Abnormal')\n",
    "    predict_df.to_csv('./predicted.csv')\n",
    "\n",
    "    print(len(predict_df))\n",
    "    print(len(givenDataFrame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday: 191033 rows\n",
      "1954\n",
      "4559\n",
      "(6513, 85)\n",
      "Best score: 0.9820454292391559\n",
      "Accuracy: 0.985553772070626\n",
      "Given DataFrame shape: (65, 77)\n",
      "Label shape: (65,)\n",
      "Labels: [0 1]\n",
      "1.\t#53\t0.104\tAvg Bwd Segment Size\n",
      "2.\t#3\t0.089\tTotal Length of Fwd Packets\n",
      "3.\t#65\t0.080\tInit_Win_bytes_forward\n",
      "4.\t#39\t0.059\tPacket Length Mean\n",
      "5.\t#4\t0.052\tTotal Length of Bwd Packets\n",
      "6.\t#12\t0.042\tBwd Packet Length Std\n",
      "7.\t#66\t0.042\tInit_Win_bytes_backward\n",
      "8.\t#11\t0.040\tBwd Packet Length Mean\n",
      "{(65, 77)}\n",
      "{(65,)}\n",
      "65\n",
      "65\n",
      "Total: 191033\n",
      "RandomForestClassifier(max_depth=13, max_features=8, min_samples_leaf=2,\n",
      "                       n_estimators=20)\n",
      "{'max_depth': 13, 'max_features': 8, 'min_samples_leaf': 2, 'n_estimators': 20}\n",
      "0.9820454292391559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total = 0\n",
    "for day in days:\n",
    "     # Filter & merge dataset by day\n",
    "    paths = list(filter(lambda s: s.startswith(day), csv_files))\n",
    "    rawDataFrame = None\n",
    "    for path in paths:\n",
    "        absolute_path = f'/Users/emmap/Downloads/TrafficLabelling/{path}'\n",
    "        if rawDataFrame is None:\n",
    "             rawDataFrame = pd.read_csv(absolute_path)\n",
    "        else:\n",
    "             rawDataFrame = pd.concat([rawDataFrame, pd.read_csv(absolute_path)])\n",
    "\n",
    "    total += len(rawDataFrame.index)\n",
    "    print(f'{day}: {len(rawDataFrame.index)} rows')\n",
    "    rawDataFrame = rawDataFrame.rename(columns=lambda s: s.strip())\n",
    "    balance_df = balancing(rawDataFrame)\n",
    "    print(balance_df.shape)\n",
    "    model_config = hyperparameter_selection(balance_df)\n",
    "    # Random sampling of the dataframe to pass to \"score\"\n",
    "    sample_balance = balance_df.sample(frac = 0.01)\n",
    "    score(sample_balance, model_config)\n",
    "    sample_balance.to_csv('./balance.csv', index=False)\n",
    "\n",
    "\n",
    "print(f'Total: {total}')\n",
    "print(model_config[0])\n",
    "print(model_config[1])\n",
    "print(model_config[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b2a03a112ba86568a4c06260438c739515f1cf7c30783eb02b54f2bb6af7b74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
